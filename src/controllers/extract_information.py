from ..database.connect import client
from langchain_community.embeddings.ollama import OllamaEmbeddings
from langchain.vectorstores.mongodb_atlas import MongoDBAtlasVectorSearch
from langchain.document_loaders.directory import DirectoryLoader
from langchain.llms.ollama import Ollama
from langchain.chains.retrieval_qa.base import RetrievalQA
import gradio as gr
from gradio.themes.base import Base
from ..core.config import settings

dbName = "rag_langchain_demo"
collectionName = "collection_of_txt_blobs"
collection = client[dbName][collectionName]

loader = DirectoryLoader("assets", glob="*.txt", show_progress=True)
data = loader.load()

embeddings = OllamaEmbeddings(base_url=settings.OLLAMA_URL, model="mistral")

vectorStore = MongoDBAtlasVectorSearch.from_documents(
    data, embeddings, collection=collection
)


def query_data(query):
    docs = vectorStore.similarity_search(query, k=1)
    as_output = docs[0].page_content
    # Spin up Ollama Server in Local
    llm = Ollama(base_url=settings.OLLAMA_URL, model="mistral")
    retriever = vectorStore.as_retriever()
    qa = RetrievalQA.from_chain_type(llm, chain_type="stuff", retriever=retriever)
    retriever_output = qa.run(query)
    return as_output, retriever_output


def create_gradio_ui() -> gr.Blocks:
    with gr.Blocks(
        theme=Base(), title="Question Answering App using Vector Search & RAG"
    ) as demo:
        gr.Markdown(
            """
            Question Answering App using Vector Search & RAG Architecture
            """
        )
        textbox = gr.Textbox(label="Enter your Questions:")
        with gr.Row():
            button = gr.Button("Submit", variant="primary")
        with gr.Column():
            output1 = gr.Textbox(
                lines=1,
                max_lines=10,
                label="Output with just Atlas Vector Search (returns text field as is):",
            )
            output2 = gr.Textbox(
                lines=1,
                max_lines=10,
                label="Output generated by chaining Atlas Vector Search to Langchain's RetrivalQA + Ollama LLM:",
            )

        button.click(query_data, textbox, outputs=[output1, output2])
    return demo
